{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "695c021a-c499-48b3-8408-4136a56f7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference:\n",
    "#https://www.kaggle.com/code/arunklenin/fake-news-classifier-with-bidirectional-lstm-99-1/notebook\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "import pandas.core.algorithms as algos\n",
    "pd.pandas.set_option('display.max_columns',None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477cdb26-4b37-4e8b-96ba-0d04cd6b18db",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf054fc-8b5a-4a35-a91e-bf7fa77095c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset datacommons_factcheck (C:/Users/Reza/.cache/huggingface/datasets/datacommons_factcheck/fctchk_politifact_wapo/1.0.0/e3861c84c3e449fb0c316b75997e30bbf723e2ca7f33c668bda07b7436567b35)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1e46f6cd1f458987cf9ca8f555c894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': ['reviewer_name', 'claim_text', 'review_date', 'review_url', 'review_rating', 'claim_author_name', 'claim_date']}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "from huggingface_hub import list_datasets\n",
    "\n",
    "dataset = load_dataset(\"datacommons_factcheck\", \"fctchk_politifact_wapo\")\n",
    "print(dataset.column_names)\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "#print(df[['claim_text','review_rating']].head(10).to_markdown())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c222c-2031-441a-acf6-21516dce18f2",
   "metadata": {},
   "source": [
    "#\n",
    "Cleaning the 'review_rating' column\n",
    "For cleaning this column I used common methods, except removing the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdb51295-7061-4c8f-9c34-738b5bbc80e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Reza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Reza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55695012-e2e2-49ff-a587-5d6852b6f6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8276f720-c584-4dfa-b012-4f794afee0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet=WordNetLemmatizer()\n",
    "stemmer=PorterStemmer()\n",
    "def clean(text):\n",
    "    # text=\"\".join([char for char in text if char not in string.punctuation])\n",
    "    text=\"\".join([re.sub('[^a-zA-Z]',' ',char) for char in text ])\n",
    "    text=text.lower()\n",
    "    text=text.split()\n",
    "    #text=[stemmer.stem(word) for word in text if word not in set(stopwords.words(\"english\"))]\n",
    "    text=\" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d6477e-6be1-41fa-a746-d826840cc5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5632, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train.shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35df276e-04f1-47ff-83b8-381640913626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                  pants on fire\n",
      "1                      half true\n",
      "2       will military drills end\n",
      "3                          false\n",
      "4                           true\n",
      "                  ...           \n",
      "5627                   half true\n",
      "5628                       false\n",
      "5629               needs context\n",
      "5630                  misleading\n",
      "5631                       false\n",
      "Name: review_rating, Length: 5632, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['review_rating'] = df['review_rating'].apply(clean)\n",
    "#print('len(ser1)=',len(ser1))\n",
    "print(df['review_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c75534b-c496-4a64-a101-4fab94d570a9",
   "metadata": {},
   "source": [
    "#\n",
    "For creating the labels I used a sentiment analysis method to find out the sentiment of the user for that label, then I classified the labels according to the resulted sentiment values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aaafcc1-a053-4e53-98df-30c1df15d57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(x_all)=  374\n",
      "sum =  5279\n",
      "len(x_new), x_new= 36 [('false', 1304), ('mostly false', 672), ('pants on fire', 666), ('half true', 645), ('mostly true', 594), ('true', 343), ('four pinocchios', 246), ('three pinocchios', 160), ('two pinocchios', 112), ('distorts the facts', 84), ('not the whole story', 72), ('misleading', 60), ('no evidence', 52), ('spins the facts', 44), ('needs context', 36), ('full flop', 22), ('unsupported', 21), ('lacks context', 19), ('geppetto checkmark', 14), ('flip flop', 14), ('exaggerates', 13), ('cherry picks', 11), ('one pinocchio', 10), ('wrong', 10), ('exagerated', 8), ('half flip', 7), ('out of context', 7), ('not quite right', 5), ('disputed', 5), ('in dispute', 4), ('verdict pending', 4), ('needs more context', 3), ('false distorts facts', 3), ('no way to know', 3), ('spinning the facts', 3), ('satire', 3)]\n"
     ]
    }
   ],
   "source": [
    "import collections as cl\n",
    "x_all = cl.Counter()\n",
    "\n",
    "for word in df['review_rating']:\n",
    "    x_all[word]+=1\n",
    "print('len(x_all)= ',len(x_all))\n",
    "x_all= sorted(x_all.items(), key=lambda pair: pair[1], reverse=True)\n",
    "\n",
    "review_rating = [x for x in x_all if x[1]>2]\n",
    "print('sum = ',sum(row[1] for row in review_rating))\n",
    "print('len(x_new), x_new=',len(review_rating),review_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eb9c8a0-0d40-40af-adde-df5007f7975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_rating_uq=[item[0] for item in review_rating]\n",
    "review_rating_uq = pd.DataFrame(review_rating_uq, columns=['review_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c4f2a43-4a6d-4f95-8039-3a87dc2ed7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Reza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#features=[i for i  in train.columns if i not in ['label']]\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "corpus = list(review_rating_uq['review_rating'])\n",
    "sentimentscores = []\n",
    "for i in corpus:\n",
    "    score = sia.polarity_scores(i)\n",
    "    score['review_rating'] = i\n",
    "    sentimentscores.append(score)\n",
    "    \n",
    "sentimentdf = pd.DataFrame(sentimentscores)\n",
    "#sentimentdf.drop(columns=['review_rating'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e41f595-61e8-413a-9a9f-df6d845ed9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>review_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>mostly false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>pants on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>half true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>mostly true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>four pinocchios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>three pinocchios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>two pinocchios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>distorts the facts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>not the whole story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4019</td>\n",
       "      <td>misleading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.688</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>no evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>spins the facts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>needs context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.706</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>full flop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4019</td>\n",
       "      <td>unsupported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>lacks context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>geppetto checkmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.706</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>flip flop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>exaggerates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>cherry picks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>one pinocchio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>exagerated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>half flip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>out of context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>not quite right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>disputed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.730</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4019</td>\n",
       "      <td>in dispute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>verdict pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>needs more context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>false distorts facts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.423</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>no way to know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>spinning the facts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>satire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      neg    neu    pos  compound         review_rating\n",
       "0   0.000  1.000  0.000    0.0000                 false\n",
       "1   0.000  1.000  0.000    0.0000          mostly false\n",
       "2   0.545  0.455  0.000   -0.3400         pants on fire\n",
       "3   0.000  0.263  0.737    0.4215             half true\n",
       "4   0.000  0.263  0.737    0.4215           mostly true\n",
       "5   0.000  0.000  1.000    0.4215                  true\n",
       "6   0.000  1.000  0.000    0.0000       four pinocchios\n",
       "7   0.000  1.000  0.000    0.0000      three pinocchios\n",
       "8   0.000  1.000  0.000    0.0000        two pinocchios\n",
       "9   0.545  0.455  0.000   -0.3400    distorts the facts\n",
       "10  0.000  1.000  0.000    0.0000   not the whole story\n",
       "11  1.000  0.000  0.000   -0.4019            misleading\n",
       "12  0.688  0.312  0.000   -0.2960           no evidence\n",
       "13  0.000  1.000  0.000    0.0000       spins the facts\n",
       "14  0.000  1.000  0.000    0.0000         needs context\n",
       "15  0.706  0.294  0.000   -0.3400             full flop\n",
       "16  1.000  0.000  0.000   -0.4019           unsupported\n",
       "17  0.000  1.000  0.000    0.0000         lacks context\n",
       "18  0.000  1.000  0.000    0.0000    geppetto checkmark\n",
       "19  0.706  0.294  0.000   -0.3400             flip flop\n",
       "20  1.000  0.000  0.000   -0.1531           exaggerates\n",
       "21  0.000  1.000  0.000    0.0000          cherry picks\n",
       "22  0.000  1.000  0.000    0.0000         one pinocchio\n",
       "23  1.000  0.000  0.000   -0.4767                 wrong\n",
       "24  0.000  1.000  0.000    0.0000            exagerated\n",
       "25  0.000  1.000  0.000    0.0000             half flip\n",
       "26  0.000  1.000  0.000    0.0000        out of context\n",
       "27  0.000  1.000  0.000    0.0000       not quite right\n",
       "28  1.000  0.000  0.000   -0.3400              disputed\n",
       "29  0.730  0.270  0.000   -0.4019            in dispute\n",
       "30  0.000  0.385  0.615    0.1531       verdict pending\n",
       "31  0.000  1.000  0.000    0.0000    needs more context\n",
       "32  0.545  0.455  0.000   -0.3400  false distorts facts\n",
       "33  0.423  0.577  0.000   -0.2960        no way to know\n",
       "34  0.000  1.000  0.000    0.0000    spinning the facts\n",
       "35  0.000  1.000  0.000    0.0000                satire"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimentdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "072e6bac-c6fd-403c-a2ac-2b356599652e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     reviewer_name                                         claim_text  \\\n",
      "0       PolitiFact  Quotes Michelle Obama as saying, \"White folks ...   \n",
      "1       PolitiFact  Says Facebook shut down a \"Chick-Fil-A Appreci...   \n",
      "2       PolitiFact  \"We haven’t given up anything other than … I a...   \n",
      "3    FactCheck.org  \"BREAKING: 2 Democrat Congressmen On ISIS Payr...   \n",
      "4       PolitiFact  The \"Dallas Cowboys can’t put a sticker on the...   \n",
      "5       PolitiFact  Tom Suozzi raised taxes \"by hundreds of millio...   \n",
      "6       PolitiFact  \"Corporate entities are paying a lot less taxe...   \n",
      "7  Washington Post  \"Violent crime is now going down for the first...   \n",
      "8       PolitiFact  \"Some of the safest communities in the United ...   \n",
      "9       PolitiFact  \"For all of those (DACA) that are concerned ab...   \n",
      "\n",
      "               review_rating                            claim_author_name  \n",
      "0              pants on fire                               Facebook posts  \n",
      "1                  half true                                     Ted Cruz  \n",
      "2   will military drills end                                 Donald Trump  \n",
      "3                      false                             Various websites  \n",
      "4                       true                                  James Woods  \n",
      "5                       true  National Republican Congressional Committee  \n",
      "6                mostly true                                 Kip Kendrick  \n",
      "7            four pinocchios                                 Donald Trump  \n",
      "8                mostly true                                  Jorge Ramos  \n",
      "9  multiple ways to evaluate                                 Donald Trump  \n"
     ]
    }
   ],
   "source": [
    "data = df[['reviewer_name', 'claim_text', 'review_rating','claim_author_name']]\n",
    "#positive_word_set = ['true' , 'one' , 'two' , 'whole' , 'geppetto' , 'exag' , 'right', 'context', 'pants' ]\n",
    "positive_word_set = ['true' , 'one' , 'two' , 'whole' , 'geppetto' , 'exag' , 'right']\n",
    "#data.insert(len(data.columns),'label',0)\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0296a873-2773-469a-ab30-38409127d661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632\n",
      "n_flag_true= 1829\n",
      "5632\n",
      "5632\n",
      "                  review_rating  label\n",
      "0                 pants on fire      0\n",
      "1                     half true      1\n",
      "2      will military drills end      0\n",
      "3                         false      0\n",
      "4                          true      1\n",
      "5                          true      1\n",
      "6                   mostly true      1\n",
      "7               four pinocchios      0\n",
      "8                   mostly true      1\n",
      "9     multiple ways to evaluate      0\n",
      "10  mostly entered before obama      0\n",
      "11                 mostly false      0\n",
      "12                  mostly true      1\n",
      "13                pants on fire      0\n",
      "14                  mostly true      1\n",
      "15                  mostly true      1\n",
      "16                pants on fire      0\n",
      "17                         true      1\n",
      "18                 mostly false      0\n",
      "19                pants on fire      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reza\\AppData\\Local\\Temp\\ipykernel_3428\\1938735809.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['label']=labels\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = []\n",
    "\n",
    "print(len(data[['review_rating']]))\n",
    "n_flag_true = 0\n",
    "for words in data[['review_rating']].iterrows():\n",
    "    words = str(words)\n",
    "    #print(words,end='|')\n",
    "    words = words.lower()\n",
    "    flag = False\n",
    "    for word in positive_word_set:\n",
    "        if word in words:\n",
    "            flag = True\n",
    "            n_flag_true += 1\n",
    "            break\n",
    "    if flag:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "print(\"n_flag_true=\" , n_flag_true)\n",
    "#print(label)        \n",
    "#label = pd.DataFrame(data = label, columns=['label'])\n",
    "\n",
    "data['label']=labels\n",
    "print(len(labels))\n",
    "print(len(data))\n",
    "#pd.set_option('display.max_rows', None)\n",
    "print(data[['review_rating','label']].iloc[:20])\n",
    "\n",
    "#data=data.drop(labels=['label'],axis=1,inplace=False)\n",
    "#data=data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f225c5a-121f-4d01-9754-f9729321075b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5632 entries, 0 to 5631\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   reviewer_name      5632 non-null   object\n",
      " 1   claim_text         5632 non-null   object\n",
      " 2   review_rating      5632 non-null   object\n",
      " 3   claim_author_name  5632 non-null   object\n",
      " 4   label              5632 non-null   int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 220.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1879c24-4895-47e5-b8de-f0581da7b746",
   "metadata": {},
   "source": [
    "#\n",
    "Handle Missing Values\n",
    "\n",
    "There are Missing values where author name is not available, to make this meaningful let us fill the missing values with \"unavailable\" and this would be concistent for authorless titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "273b3a2b-67f8-4d6b-8955-0e603be85ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reza\\AppData\\Local\\Temp\\ipykernel_3428\\1215144964.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.fillna('unavailable',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.fillna('unavailable',inplace=True)\n",
    "#test=pd.read_csv('fake-news/test.csv')\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26b0aef2-766a-4b09-b5ef-1ec6a3bec6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "#'reviewer_name', 'claim_text', 'review_rating','claim_author_name'\n",
    "data_comb = copy.deepcopy(data)\n",
    "data_comb['comb']=data['reviewer_name']+\"_\"+data['claim_text']      # Combined all the features\n",
    "#data_comb = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e9fa20e-75dd-4958-a84b-f692f987c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet=WordNetLemmatizer()\n",
    "stemmer=PorterStemmer()\n",
    "def clean(text):\n",
    "    # text=\"\".join([char for char in text if char not in string.punctuation])\n",
    "    text=\"\".join([re.sub('[^a-zA-Z]',' ',char) for char in text ])\n",
    "    text=text.lower()\n",
    "    text=text.split()\n",
    "    text=[stemmer.stem(word) for word in text if word not in set(stopwords.words(\"english\"))]\n",
    "    text=\" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee0332c6-e04c-40c1-8716-a742ff6c7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comb['comb']=data_comb['comb'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00342e08-418c-4d4e-8851-2fecdc439f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>claim_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>claim_author_name</th>\n",
       "      <th>label</th>\n",
       "      <th>comb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PolitiFact</td>\n",
       "      <td>Quotes Michelle Obama as saying, \"White folks ...</td>\n",
       "      <td>pants on fire</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>0</td>\n",
       "      <td>politifact quot michel obama say white folk wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PolitiFact</td>\n",
       "      <td>Says Facebook shut down a \"Chick-Fil-A Appreci...</td>\n",
       "      <td>half true</td>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>1</td>\n",
       "      <td>politifact say facebook shut chick fil appreci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PolitiFact</td>\n",
       "      <td>\"We haven’t given up anything other than … I a...</td>\n",
       "      <td>will military drills end</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>0</td>\n",
       "      <td>politifact given anyth agre meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FactCheck.org</td>\n",
       "      <td>\"BREAKING: 2 Democrat Congressmen On ISIS Payr...</td>\n",
       "      <td>false</td>\n",
       "      <td>Various websites</td>\n",
       "      <td>0</td>\n",
       "      <td>factcheck org break democrat congressmen isi p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PolitiFact</td>\n",
       "      <td>The \"Dallas Cowboys can’t put a sticker on the...</td>\n",
       "      <td>true</td>\n",
       "      <td>James Woods</td>\n",
       "      <td>1</td>\n",
       "      <td>politifact dalla cowboy put sticker helmet pol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewer_name                                         claim_text  \\\n",
       "0     PolitiFact  Quotes Michelle Obama as saying, \"White folks ...   \n",
       "1     PolitiFact  Says Facebook shut down a \"Chick-Fil-A Appreci...   \n",
       "2     PolitiFact  \"We haven’t given up anything other than … I a...   \n",
       "3  FactCheck.org  \"BREAKING: 2 Democrat Congressmen On ISIS Payr...   \n",
       "4     PolitiFact  The \"Dallas Cowboys can’t put a sticker on the...   \n",
       "\n",
       "              review_rating claim_author_name  label  \\\n",
       "0             pants on fire    Facebook posts      0   \n",
       "1                 half true          Ted Cruz      1   \n",
       "2  will military drills end      Donald Trump      0   \n",
       "3                     false  Various websites      0   \n",
       "4                      true       James Woods      1   \n",
       "\n",
       "                                                comb  \n",
       "0  politifact quot michel obama say white folk wr...  \n",
       "1  politifact say facebook shut chick fil appreci...  \n",
       "2                   politifact given anyth agre meet  \n",
       "3  factcheck org break democrat congressmen isi p...  \n",
       "4  politifact dalla cowboy put sticker helmet pol...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85c05a3e-4aa9-46fb-bf8d-8075ad78dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07a1beb6-7d27-4ef5-93af-bcbc20419d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size=30000   # Vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85e987ef-4a66-4495-b7e5-c4410adc1be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'politifact quot michel obama say white folk wrong america'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=data_comb['comb']\n",
    "title[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf020ca9-4a28-40e3-ba42-2b22edafa54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_r=[one_hot(words, voc_size) for words in title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "113e93d7-479b-43d0-9185-d4b63409494e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9632, 7202, 12520, 27172, 13506, 24429, 9753, 11858, 14008],\n",
       " [9632, 13506, 19241, 16547, 1667, 19387, 14395, 28574]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_r[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7e18797-8214-487e-ba1e-02e20f4f9c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_len=50\n",
    "embedded_docs=pad_sequences(one_hot_r,padding='post',maxlen=sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3977e150-d5f9-4cd0-94d2-c3d296bbb78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9632,  7202, 12520, 27172, 13506, 24429,  9753, 11858, 14008,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [ 9632, 13506, 19241, 16547,  1667, 19387, 14395, 28574,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [ 9632, 28735, 13930,  8690,  3845,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [ 7242, 16958,  4079, 28380,  1262, 10660, 16566,  1723, 22814,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [ 9632,  2910,  4418, 23808, 12825,  7980,  2496, 21733, 18125,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [ 9632, 10228, 28926,  7495, 10936, 14102,  5087, 13594, 11437,\n",
       "        20117, 29599,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [ 9632, 23143, 26444, 28273, 28362, 19040, 10936,  2413, 14996,\n",
       "        16920,  6717,  1619, 17803,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [ 8511,  7340, 21145,  9071, 23091,  6541,  9222, 17928,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [ 9632, 22418, 13636, 14246, 29566, 23637,  8077,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [ 9632, 22958,  5266, 10737, 28912, 14840, 22617, 20890, 28944,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "000e8efd-367c-46ea-b2dc-b28b3ebec71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd=tensorflow.keras.optimizers.SGD(learning_rate=0.01,momentum=0.9, nesterov=True)\n",
    "rms = tensorflow.keras.optimizers.RMSprop()\n",
    "nadam=tensorflow.keras.optimizers.Nadam(\n",
    "learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Nadam\")\n",
    "embedding_vector_features=50\n",
    "def create_model():\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_len))\n",
    "    # model.add(Dropout(0.1))\n",
    "    model.add(Bidirectional(LSTM(100)))  # used Bidirectional LSTM\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer=nadam,metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60d5b733-6c7b-46e1-b542-e4f761f62d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 50, 50)            1500000   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 200)              120800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,621,001\n",
      "Trainable params: 1,621,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bebe1e0b-d24b-44ec-a2f9-205adf5de2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5632"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89cb5fe2-7d86-4669-9371-562548e48142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ddd1838c-2a0d-4899-96e0-7e08271397c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=int(data.shape[0]*0.9)\n",
    "X=embedded_docs[:l]\n",
    "y=data['label'][:l]\n",
    "x_test=embedded_docs[l:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9f62579-0d3c-4dab-a213-5d8e23406a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5068\n",
      "5068\n",
      "5068\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(l)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "41438f6a-7bf1-4aa7-8e92-c638889352a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "10041445-ad10-48f4-ae96-8da2002e06c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint',\n",
       " 'fake_news_model_wights.ckpt.data-00000-of-00001',\n",
       " 'fake_news_model_wights.ckpt.index']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "checkpoint_path = \"trained_model/fake_news_model_wights.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63ebb484-e154-4b43-89e4-50c69a473c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "model.trainable = False\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "model.compile(loss='binary_crossentropy',optimizer=nadam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a70e255a-a537-47c5-acdf-9a81225e469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"trained_model/fine_tuning.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c3c1a828-26e7-4ef4-92e7-bc2a66cf39eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 579, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 695, in apply_gradients\n        self._create_all_weights(var_list)\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 959, in _create_all_weights\n        self._create_slots(var_list)\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\nadam.py\", line 95, in _create_slots\n        var_dtype = var_list[0].dtype.base_dtype\n\n    IndexError: list index out of range\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m124\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1233\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1234\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mStagingError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 579, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 695, in apply_gradients\n        self._create_all_weights(var_list)\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 959, in _create_all_weights\n        self._create_slots(var_list)\n    File \"C:\\Users\\Reza\\.conda\\envs\\tf_gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\nadam.py\", line 95, in _create_slots\n        var_dtype = var_list[0].dtype.base_dtype\n\n    IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(x_valid,y_valid),epochs=2,batch_size=124, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fba7e-723a-4916-b007-c966a7aabe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob=np.array(model.predict(X_train))[:,0]\n",
    "y_pred_valid=np.array(model.predict(x_valid))[:,0]\n",
    "y_pred=np.array(model.predict(x_test))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b298eae1-2edb-416e-af53-46dcc43c436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_valid, y_pred_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95efdd22-f38e-4f1a-bf56-ef7541439c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "[...]\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667e609a-d53e-4854-9d21-c5e12a52f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[]\n",
    "B=[]\n",
    "C=[]\n",
    "for i in range(len(thresholds)):\n",
    "    predicted = pd.DataFrame()\n",
    "    predicted[\"label\"] = y_pred_prob\n",
    "    predicted[\"label\"] = np.where(predicted[\"label\"] > float(thresholds[i]), 1, 0)\n",
    "    pred_valid = pd.DataFrame()\n",
    "    pred_valid[\"label\"] = y_pred_valid\n",
    "    pred_valid[\"label\"] = np.where(pred_valid[\"label\"] > float(thresholds[i]), 1, 0)\n",
    "    A.append(metrics.accuracy_score(y_train, predicted))\n",
    "    B.append(metrics.accuracy_score(y_valid, pred_valid))\n",
    "    C.append(thresholds[i])\n",
    "acc=pd.DataFrame(C,columns=['threshold'])\n",
    "acc['train_acc']=A\n",
    "acc['test_acc']=B\n",
    "acc.sort_values(by='test_acc',ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b845759-af11-4874-ba36-c54a6ad45e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283040bb-d683-46c9-8d6c-df9a513dffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff=acc.iloc[0,0]\n",
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b87024-8c0e-42f9-bfa5-c71b0a06a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame()\n",
    "predicted[\"label\"] = y_pred_prob\n",
    "predicted[\"label\"] = np.where(predicted[\"label\"] > float(cutoff), 1, 0)\n",
    "predicted\n",
    "\n",
    "pred_valid = pd.DataFrame()\n",
    "pred_valid[\"label\"] = y_pred_valid\n",
    "pred_valid[\"label\"] = np.where(pred_valid[\"label\"] > float(cutoff), 1, 0)\n",
    "pred_valid\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['label'] = y_pred\n",
    "predictions['label'] = np.where(predictions['label'] > float(cutoff), 1, 0)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b47e1d-b27a-46dc-9748-9742bda87d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b9c49-700e-400f-8d62-c1b9c637e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = metrics.confusion_matrix(y_train, predicted)\n",
    "print(conf_matrix)\n",
    "acc_train = metrics.accuracy_score(y_train, predicted)\n",
    "print('Accuracy: ',acc_train)\n",
    "precision_train = metrics.precision_score(y_train, predicted)\n",
    "print('Presicion: ',precision_train)\n",
    "sensitivity_train = metrics.recall_score(y_train, predicted)\n",
    "print('Recall: ',sensitivity_train)\n",
    "specificity_train = conf_matrix[0,0] / (conf_matrix[0,0] + conf_matrix[0,1])\n",
    "print('Specificity: ',specificity_train)\n",
    "roc_auc_score(y_train, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ce58e-3f74-45e5-9608-a7cafc87a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = metrics.confusion_matrix(y_valid, pred_valid)\n",
    "print(conf_matrix)\n",
    "\n",
    "acc_train = metrics.accuracy_score(y_valid, pred_valid)\n",
    "print('Accuracy: ',acc_train)\n",
    "precision_train = metrics.precision_score(y_valid, pred_valid)\n",
    "print('Precision: ',precision_train)\n",
    "sensitivity_train = metrics.recall_score(y_valid, pred_valid)\n",
    "print('Recall: ',sensitivity_train)\n",
    "specificity_train = conf_matrix[0,0] / (conf_matrix[0,0] + conf_matrix[0,1])\n",
    "print('Specificity: ',specificity_train)\n",
    "roc_auc_score(y_valid, pred_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a2b84-2f98-4f8f-8f6a-18d70cd3bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_train, predicted,average='macro'))\n",
    "f1_score(y_valid, pred_valid,average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
